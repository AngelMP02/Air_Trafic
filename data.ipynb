{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos y filtramos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\Angel Mart√≠nez\\\\Documents\\\\GitHub\\\\Air_Trafic\\\\archivo_sin_duplicados.csv\\\\0.part']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el conjunto de datos en un dataframe de Dask\n",
    "df = dd.read_csv('air_traffic_data.csv')\n",
    "\n",
    "# Eliminar registros duplicados\n",
    "df_air_filt= df.drop_duplicates()\n",
    "\n",
    "# Volcar los resultados en un archivo CSV\n",
    "df_air_filt.to_csv('archivo_sin_duplicados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity Period</th>\n",
       "      <th>Operating Airline</th>\n",
       "      <th>Operating Airline IATA Code</th>\n",
       "      <th>Published Airline</th>\n",
       "      <th>Published Airline IATA Code</th>\n",
       "      <th>GEO Summary</th>\n",
       "      <th>GEO Region</th>\n",
       "      <th>Activity Type Code</th>\n",
       "      <th>Price Category Code</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>Boarding Area</th>\n",
       "      <th>Passenger Count</th>\n",
       "      <th>Adjusted Activity Type Code</th>\n",
       "      <th>Adjusted Passenger Count</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: drop-duplicates-agg, 3 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Activity Period Operating Airline Operating Airline IATA Code Published Airline Published Airline IATA Code GEO Summary GEO Region Activity Type Code Price Category Code Terminal Boarding Area Passenger Count Adjusted Activity Type Code Adjusted Passenger Count   Year   Month\n",
       "npartitions=1                                                                                                                                                                                                                                                                                     \n",
       "                        int64            object                      object            object                      object      object     object             object              object   object        object           int64                      object                    int64  int64  object\n",
       "                          ...               ...                         ...               ...                         ...         ...        ...                ...                 ...      ...           ...             ...                         ...                      ...    ...     ...\n",
       "Dask Name: drop-duplicates-agg, 3 tasks"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "Activity Period    int64\n",
       "Year                 ...\n",
       "dtype: int64\n",
       "Dask Name: dataframe-sum-agg, 6 tasks"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conteo de valores perdidos/faltantes  \n",
    "df_air_filt.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 16 entries, Activity Period to Month\n",
      "dtypes: object(12), int64(4)"
     ]
    }
   ],
   "source": [
    "df_air_filt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Activity Period                 int64\n",
       "Operating Airline              object\n",
       "Operating Airline IATA Code    object\n",
       "Published Airline              object\n",
       "Published Airline IATA Code    object\n",
       "GEO Summary                    object\n",
       "GEO Region                     object\n",
       "Activity Type Code             object\n",
       "Price Category Code            object\n",
       "Terminal                       object\n",
       "Boarding Area                  object\n",
       "Passenger Count                 int64\n",
       "Adjusted Activity Type Code    object\n",
       "Adjusted Passenger Count        int64\n",
       "Year                            int64\n",
       "Month                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consultamos el tipo de datos\n",
    "df_air_filt.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Operating Airline              object\n",
       "Operating Airline IATA Code    object\n",
       "Published Airline              object\n",
       "Published Airline IATA Code    object\n",
       "GEO Summary                    object\n",
       "GEO Region                     object\n",
       "Activity Type Code             object\n",
       "Price Category Code            object\n",
       "Terminal                       object\n",
       "Boarding Area                  object\n",
       "Adjusted Activity Type Code    object\n",
       "Month                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air_filt.dtypes[df_air_filt.dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_drop= [\"GEO Region\",\n",
    "                \"GEO Summary\",\n",
    "                \"Price Category Code\",\n",
    "                \"Adjusted Activity Type Code\",\n",
    "                \"Price Category Code\",\n",
    "                \"Activity Type Code\" ,\n",
    "                \"Operating Airline IATA Code\",\n",
    "                \"Operating Airline IATA Code\",\n",
    "                \"Published Airline IATA Code\",\n",
    "                \"Published Airline\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air_filt= df_air_filt.drop(columns=columnas_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Terminal 1\n",
      "1    International\n",
      "2       Terminal 3\n",
      "3            Other\n",
      "4       Terminal 2\n",
      "Name: Terminal, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valores_unicos = df_air_filt['Terminal'].unique().compute()\n",
    "\n",
    "\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Terminal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Terminal_numeros = {\n",
    "    'Terminal 1': 1,\n",
    "    'Terminal 2': 2,\n",
    "    'Terminal 3': 3,\n",
    "    'Internacional':4,\n",
    "}\n",
    "\n",
    "\n",
    "df_air_filt[\"Terminal\"]=df_air_filt[\"Terminal\"].map(Terminal_numeros)\n",
    "print(df_air_filt[\"Terminal\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Operating Airline    object\n",
       "Boarding Area        object\n",
       "Month                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air_filt.dtypes[df_air_filt.dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15002    3\n",
      "15003    3\n",
      "15004    3\n",
      "15005    3\n",
      "15006    3\n",
      "Name: Month, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meses_numeros = {\n",
    "    'January': 1,\n",
    "    'February': 2,\n",
    "    'March': 3,\n",
    "    'April': 4,\n",
    "    'May': 5,\n",
    "    'June': 6,\n",
    "    'July': 7,\n",
    "    'August': 8,\n",
    "    'September': 9,\n",
    "    'October': 10,\n",
    "    'November': 11,\n",
    "    'December': 12\n",
    "}\n",
    "df_air_filt[\"Month\"]=df_air_filt[\"Month\"].map(meses_numeros)\n",
    "print(df_air_filt[\"Month\"].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        B\n",
      "1        G\n",
      "2        A\n",
      "3        E\n",
      "4        C\n",
      "5        F\n",
      "6    Other\n",
      "7        D\n",
      "Name: Boarding Area, dtype: object\n"
     ]
    }
   ],
   "source": [
    "valores_unicos = df_air_filt['Boarding Area'].unique().compute()\n",
    "\n",
    "\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "    float64\n",
       "        ...\n",
       "Name: Boarding Area, dtype: float64\n",
       "Dask Name: getitem, 15 tasks"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "boarding_area = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    'D': 4,\n",
    "    'E': 5,\n",
    "    'F':6,\n",
    "    'G':7\n",
    "    \n",
    "    }\n",
    "df_air_filt[\"Boarding Area\"]=df_air_filt[\"Boarding Area\"].map(boarding_area)\n",
    "df_air_filt[\"Boarding Area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "Activity Period    int64\n",
       "Year                 ...\n",
       "dtype: int64\n",
       "Dask Name: dataframe-sum-agg, 20 tasks"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_air_filt.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Metadata inference failed in `dropna`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nTypeError('You cannot set both the how and thresh arguments at the same time.')\n\nTraceback:\n---------\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py\", line 182, in raise_on_meta_error\n    yield\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\", line 6406, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\utils.py\", line 1070, in __call__\n    return getattr(__obj, self.method)(*args, **kwargs)\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 6537, in dropna\n    raise TypeError(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:182\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[1;34m(funcname, udf)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:6406\u001b[0m, in \u001b[0;36m_emulate\u001b[1;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6405\u001b[0m \u001b[39mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[39m=\u001b[39mudf):\n\u001b[1;32m-> 6406\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m_extract_meta(args, \u001b[39mTrue\u001b[39;00m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_extract_meta(kwargs, \u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\utils.py:1070\u001b[0m, in \u001b[0;36mmethodcaller.__call__\u001b[1;34m(self, _methodcaller__obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, __obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 1070\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(__obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6537\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[1;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[0;32m   6536\u001b[0m \u001b[39mif\u001b[39;00m (how \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m no_default) \u001b[39mand\u001b[39;00m (thresh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m no_default):\n\u001b[1;32m-> 6537\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   6538\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou cannot set both the how and thresh arguments at the same time.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6539\u001b[0m     )\n\u001b[0;32m   6541\u001b[0m \u001b[39mif\u001b[39;00m how \u001b[39mis\u001b[39;00m no_default:\n",
      "\u001b[1;31mTypeError\u001b[0m: You cannot set both the how and thresh arguments at the same time.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[298], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_air_filt2 \u001b[39m=\u001b[39m df_air_filt\u001b[39m.\u001b[39;49mdropna()\n\u001b[0;32m      2\u001b[0m df_air_filt2\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:5032\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[1;34m(self, how, subset, thresh)\u001b[0m\n\u001b[0;32m   5030\u001b[0m \u001b[39m@derived_from\u001b[39m(pd\u001b[39m.\u001b[39mDataFrame)\n\u001b[0;32m   5031\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdropna\u001b[39m(\u001b[39mself\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m, subset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, thresh\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 5032\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmap_partitions(\n\u001b[0;32m   5033\u001b[0m         M\u001b[39m.\u001b[39;49mdropna, how\u001b[39m=\u001b[39;49mhow, subset\u001b[39m=\u001b[39;49msubset, thresh\u001b[39m=\u001b[39;49mthresh, enforce_metadata\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   5034\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:866\u001b[0m, in \u001b[0;36m_Frame.map_partitions\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[39m@insert_meta_param_description\u001b[39m(pad\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[0;32m    740\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_partitions\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    741\u001b[0m     \u001b[39m\"\"\"Apply Python function on each DataFrame partition.\u001b[39;00m\n\u001b[0;32m    742\u001b[0m \n\u001b[0;32m    743\u001b[0m \u001b[39m    Note that the index and divisions are assumed to remain unchanged.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[39m    None as the division.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 866\u001b[0m     \u001b[39mreturn\u001b[39;00m map_partitions(func, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:6475\u001b[0m, in \u001b[0;36mmap_partitions\u001b[1;34m(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6468\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   6469\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m. If you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt want the partitions to be aligned, and are \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6470\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcalling `map_partitions` directly, pass `align_dataframes=False`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6471\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   6473\u001b[0m dfs \u001b[39m=\u001b[39m [df \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m args \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(df, _Frame)]\n\u001b[1;32m-> 6475\u001b[0m meta \u001b[39m=\u001b[39m _get_meta_map_partitions(args, dfs, func, kwargs, meta, parent_meta)\n\u001b[0;32m   6477\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Scalar) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args):\n\u001b[0;32m   6478\u001b[0m     layer \u001b[39m=\u001b[39m {\n\u001b[0;32m   6479\u001b[0m         (name, \u001b[39m0\u001b[39m): (\n\u001b[0;32m   6480\u001b[0m             apply,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6484\u001b[0m         )\n\u001b[0;32m   6485\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:6587\u001b[0m, in \u001b[0;36m_get_meta_map_partitions\u001b[1;34m(args, dfs, func, kwargs, meta, parent_meta)\u001b[0m\n\u001b[0;32m   6583\u001b[0m     parent_meta \u001b[39m=\u001b[39m dfs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_meta\n\u001b[0;32m   6584\u001b[0m \u001b[39mif\u001b[39;00m meta \u001b[39mis\u001b[39;00m no_default:\n\u001b[0;32m   6585\u001b[0m     \u001b[39m# Use non-normalized kwargs here, as we want the real values (not\u001b[39;00m\n\u001b[0;32m   6586\u001b[0m     \u001b[39m# delayed values)\u001b[39;00m\n\u001b[1;32m-> 6587\u001b[0m     meta \u001b[39m=\u001b[39m _emulate(func, \u001b[39m*\u001b[39margs, udf\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   6588\u001b[0m     meta_is_emulated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   6589\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:6405\u001b[0m, in \u001b[0;36m_emulate\u001b[1;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6400\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_emulate\u001b[39m(func, \u001b[39m*\u001b[39margs, udf\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   6401\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6402\u001b[0m \u001b[39m    Apply a function using args / kwargs. If arguments contain dd.DataFrame /\u001b[39;00m\n\u001b[0;32m   6403\u001b[0m \u001b[39m    dd.Series, using internal cache (``_meta``) for calculation\u001b[39;00m\n\u001b[0;32m   6404\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6405\u001b[0m     \u001b[39mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[39m=\u001b[39mudf):\n\u001b[0;32m   6406\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m_extract_meta(args, \u001b[39mTrue\u001b[39;00m), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_extract_meta(kwargs, \u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    151\u001b[0m     value \u001b[39m=\u001b[39m typ()\n\u001b[0;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[0;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:203\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[1;34m(funcname, udf)\u001b[0m\n\u001b[0;32m    194\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOriginal error is below:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m------------------------\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m )\n\u001b[0;32m    202\u001b[0m msg \u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mformat(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in `\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m funcname \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mrepr\u001b[39m(e), tb)\n\u001b[1;32m--> 203\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Metadata inference failed in `dropna`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nTypeError('You cannot set both the how and thresh arguments at the same time.')\n\nTraceback:\n---------\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py\", line 182, in raise_on_meta_error\n    yield\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\", line 6406, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\utils.py\", line 1070, in __call__\n    return getattr(__obj, self.method)(*args, **kwargs)\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 6537, in dropna\n    raise TypeError(\n"
     ]
    }
   ],
   "source": [
    "df_air_filt2 = df_air_filt.dropna()\n",
    "df_air_filt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_air_filt2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_air_filt2\u001b[39m=\u001b[39m df_air_filt2\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m df_air_filt2\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_air_filt2' is not defined"
     ]
    }
   ],
   "source": [
    "df_air_filt2= df_air_filt2.dropna().reset_index(drop=True)\n",
    "df_air_filt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_air_filt2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[275], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_air_filt2\u001b[39m.\u001b[39mdtypes[df_air_filt2\u001b[39m.\u001b[39mdtypes\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_air_filt2' is not defined"
     ]
    }
   ],
   "source": [
    "df_air_filt2.dtypes[df_air_filt2.dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeNotImplementedError",
     "evalue": "`df.column.cat.codes` with unknown categories is not supported.  Please use `column.cat.as_known()` or `df.categorize()` beforehand to ensure known categories",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeNotImplementedError\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[294], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m df_air_filt[\u001b[39m'\u001b[39m\u001b[39mOperating Airline\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_air_filt[\u001b[39m'\u001b[39m\u001b[39mOperating Airline\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Asignar un c√≥digo num√©rico a cada categor√≠a\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_air_filt[\u001b[39m'\u001b[39m\u001b[39mAirline numeric\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_air_filt[\u001b[39m'\u001b[39;49m\u001b[39mOperating Airline\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mcat\u001b[39m.\u001b[39;49mcodes\n\u001b[0;32m      6\u001b[0m \u001b[39m# Crear un diccionario de mapeo\u001b[39;00m\n\u001b[0;32m      7\u001b[0m mapeo_aerolineas \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39menumerate\u001b[39m(df_air_filt[\u001b[39m'\u001b[39m\u001b[39mOperating Airline\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcat\u001b[39m.\u001b[39mcategories))\n",
      "File \u001b[1;32mc:\\Users\\Angel Mart√≠nez\\anaconda3\\lib\\site-packages\\dask\\dataframe\\categorical.py:256\u001b[0m, in \u001b[0;36mCategoricalAccessor.codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mknown:\n\u001b[0;32m    251\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`df.column.cat.codes` with unknown categories is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported.  Please use `column.cat.as_known()` or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`df.categorize()` beforehand to ensure known categories\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    255\u001b[0m     )\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mraise\u001b[39;00m AttributeNotImplementedError(msg)\n\u001b[0;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_property_map(\u001b[39m\"\u001b[39m\u001b[39mcodes\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeNotImplementedError\u001b[0m: `df.column.cat.codes` with unknown categories is not supported.  Please use `column.cat.as_known()` or `df.categorize()` beforehand to ensure known categories"
     ]
    }
   ],
   "source": [
    "\n",
    "df_air_filt['Operating Airline'] = df_air_filt['Operating Airline'].astype('category')\n",
    "\n",
    "# Asignar un c√≥digo num√©rico a cada categor√≠a\n",
    "df_air_filt['Airline numeric'] = df_air_filt['Operating Airline'].cat.codes\n",
    "\n",
    "# Crear un diccionario de mapeo\n",
    "mapeo_aerolineas = dict(enumerate(df_air_filt['Operating Airline'].cat.categories))\n",
    "\n",
    "# Imprimir el diccionario de mapeo\n",
    "print(mapeo_aerolineas)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POR FIN tenemos el dataset limpio y con valores numericos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
